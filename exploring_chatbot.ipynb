{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:rgb(40, 40, 122); font-size:1.5em\">Exploring ChatBot</span>\n",
    "\n",
    "*Alekseev Vasiliy*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import all modules first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "import json\n",
    "from collections import *\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "---\n",
    "\n",
    "* [Models](#Selective Model: Embeddings-Based Ranking)\n",
    "    - [Selective Model: Embeddings-Based Ranking](#Selective Model: Embeddings-Based Ranking)\n",
    "\n",
    "    - [Generative Model: N-gram Language Model](#Generative Model: N-gram Language Model)\n",
    "\n",
    "    - [Generative Model: LSTM-Based Language Model](#Generative Model: LSTM-Based Language Model)\n",
    "\n",
    "* [Dialogue Example](#Dialogue Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Selective Model: Embeddings-Based Ranking\"></a>Selective Model: Embeddings-Based Ranking\n",
    "---\n",
    "We'll try to use pre-trained GoogleNews vectors & own-trained StarSpace vectors.\n",
    "\n",
    "There won't be much explaining text below, for it is the same code as was in the week 3 of the NLP Course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wv_embeddings = KeyedVectors.load_word2vec_format(\n",
    "    os.path.join('data', 'GoogleNews-vectors-negative300.bin'),\n",
    "    binary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wv_embeddings.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wv_embeddings['dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def question_to_vec(question, embeddings):\n",
    "    \"\"\"question -- a string\n",
    "       embeddings -- dict where the key is a word and a value is its embedding\n",
    "       ---\n",
    "       result -- vector representation for the question\"\"\"\n",
    "    \n",
    "    dim = embeddings['dog'].size # :)\n",
    "    result = np.zeros((dim,), dtype=np.float32)\n",
    "    words = question.split(' ')\n",
    "    \n",
    "    count = 0\n",
    "    for word in words:\n",
    "        #count += 1\n",
    "        #word = re.sub(r'[,.;:!?\"]', r'', word)\n",
    "        if word not in embeddings or not len(embeddings[word]):\n",
    "            continue\n",
    "        result += embeddings[word][:dim]\n",
    "        count += 1\n",
    "    \n",
    "    return result / max(count, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import datasets. We'll try to use each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_cornell = datasets.readCornellData(\n",
    "    os.path.join('data', 'cornell'), max_len=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_opensubs = datasets.readOpensubsData(\n",
    "    os.path.join('data', 'opensubs'), max_len=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79464"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_cornell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cesc ma tete this is my head', 'right see youre ready for the quiz'),\n",
       " ('thats because its such a nice one', 'forget french'),\n",
       " ('there', 'where'),\n",
       " ('you have my word as a gentleman', 'youre sweet'),\n",
       " ('hi', 'looks like things worked out tonight huh')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cornell[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "766016"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_opensubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('right then go straight to the office', 'don t dawdle on the way'),\n",
       " ('don t dawdle on the way', 'don t worry'),\n",
       " ('is your mother here too', 'why are you outside'),\n",
       " ('why are you outside', 'it s no fun listening to women s talk'),\n",
       " ('it s no fun listening to women s talk', 'well why don t we go in together')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_opensubs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_q_matrix(data, embeddings):\n",
    "    \"\"\"result -- embedding matrix for questions,\n",
    "           size (num_questions) x (embeddings dim)\"\"\"\n",
    "    q_matrix = np.array([\n",
    "        question_to_vec(pair[0], embeddings=embeddings) for pair in data\n",
    "    ])\n",
    "    \n",
    "    print('Shape:', q_matrix.shape)\n",
    "    \n",
    "    return q_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (79464, 300)\n"
     ]
    }
   ],
   "source": [
    "q_matrix_cornell = get_q_matrix(data_cornell, wv_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "# STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def text_prepare(text):\n",
    "    text = text.lower()\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "    text = BAD_SYMBOLS_RE.sub('', text)\n",
    "    \n",
    "    # We'll keep all words, including stopwords\n",
    "    text = ' '.join([x for x in text.split() if x]) # and x not in STOPWORDS])\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_answers(question, qa_data, q_matrix, embeddings):\n",
    "    \"\"\"qa_data [list] -- list of question-answer pairs\n",
    "       q_matrix -- see `get_q_matrix` above\n",
    "       ---\n",
    "       result -- question-answer pairs from `qa_data`\n",
    "           with questions corresponding to maximum\n",
    "           cosine similarity with `question`\"\"\"\n",
    "    \n",
    "    prepared_question = text_prepare(question)\n",
    "    question_vec = question_to_vec(prepared_question, embeddings)\n",
    "\n",
    "    similarities = cosine_similarity(\n",
    "        question_vec.reshape(1, -1),\n",
    "        q_matrix\n",
    "    ).flatten()\n",
    "\n",
    "    best_match_idx = similarities.argmax()\n",
    "\n",
    "    matching_idxs = np.where(similarities == similarities[best_match_idx])[0]\n",
    "    qa_pairs = np.array(qa_data)[matching_idxs].tolist()\n",
    "    answers = [p[1] for p in qa_pairs]\n",
    "\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how are you'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If delete stopwords, the function will return an empty question\n",
    "question = 'How are you?'\n",
    "text_prepare(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['how are you', 'scarred for life thats how i am'],\n",
      " ['how are you', 'very well thank you'],\n",
      " ['how are you honeybunch', 'is penelope in'],\n",
      " ['how are you', 'head still secure to the neck'],\n",
      " ['how are you', 'fine cant you see so yourself'],\n",
      " ['how are you', 'fine fine'],\n",
      " ['how are you', 'fine im fine how are you'],\n",
      " ['how are you', 'okay'],\n",
      " ['cornelius how are you', 'bob im okay how are you'],\n",
      " ['how are you', 'fine quite fine and your royal highness'],\n",
      " ['how are you', 'im okay'],\n",
      " ['how are you', 'good how are you'],\n",
      " ['how are you', 'all right son'],\n",
      " ['how are you', 'tired'],\n",
      " ['how are you', 'im just fine ally what about you'],\n",
      " ['how are you', 'i got fired'],\n",
      " ['wladek how are you', 'fine were fine thank you and you'],\n",
      " ['how are you', 'another young man'],\n",
      " ['how are you', 'hello macaulay come in'],\n",
      " ['how are you', 'i hate to bother you when youre laid up'],\n",
      " ['how are you', 'fine']]\n"
     ]
    }
   ],
   "source": [
    "question = 'How are you?'\n",
    "answers_pretrained = generate_answers(\n",
    "    question, data_cornell, q_matrix_cornell, wv_embeddings)\n",
    "pprint(answers_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine answers (and questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Own-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cornel's size — 79464 VS 766016 — OpenSubs size\n"
     ]
    }
   ],
   "source": [
    "print(fr\"Cornel's size — {len(data_cornell)} VS {len(data_opensubs)} — OpenSubs size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for StarSpace model training we'll take OpenSubs, as it is much bigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make file for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'data_prepared_opensubs.tsv'), 'w') as f:\n",
    "    for pair in data_opensubs:\n",
    "        f.write(pair[0] + '\\t' + pair[1] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here behind the scenes goes StarSpace model training. With parameters as in week 3:\n",
    ">`./starspace train -trainFile ./data_prepared.tsv -model StarSpaceModel -trainMode 3 -adagrad true -ngrams 1 -epoch 5 -dim 100 -similarity cosine -minCount 2 -verbose true -fileFormat labelDoc --negSearchLimit 10 -lr 0.02`\n",
    "\n",
    "Elapsed time: $\\approx 30$ min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load generated embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starspace_embeddings_opensubs = {}\n",
    "\n",
    "with open('./data/StarSpaceModelOpenSubs.tsv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for l in lines:\n",
    "    l = l.strip().split()\n",
    "    if len(l) <= 1:\n",
    "        continue\n",
    "    starspace_embeddings_opensubs[l[0]] = np.array([float(el) for el in l[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70685"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(starspace_embeddings_opensubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00344635, -0.00612465, -0.0188963 , -0.0253538 ,  0.00781904])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starspace_embeddings_opensubs['dog'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (766016, 100)\n"
     ]
    }
   ],
   "source": [
    "q_matrix_opensubs = get_q_matrix(data_opensubs, starspace_embeddings_opensubs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to ask something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['how are you how are you', 'betty and rodney where s ted carter'],\n",
      " ['how are you how are you', 'how is he']]\n"
     ]
    }
   ],
   "source": [
    "question = 'How are you?'\n",
    "answers_opensubs = generate_answers(\n",
    "    question, data_opensubs, q_matrix_opensubs,\n",
    "    starspace_embeddings_opensubs\n",
    ")\n",
    "pprint(answers_opensubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so good answers. Let's try also Cornell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'data_prepared_cornell.tsv'), 'w') as f:\n",
    "    for pair in data_cornell:\n",
    "        f.write(pair[0] + '\\t' + pair[1] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now learning takes $\\approx 3$ min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starspace_embeddings_cornell = {}\n",
    "\n",
    "with open('./data/StarSpaceModelCornell.tsv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for l in lines:\n",
    "    l = l.strip().split()\n",
    "    if len(l) <= 1:\n",
    "        continue\n",
    "    starspace_embeddings_cornell[l[0]] = np.array([float(el) for el in l[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16085"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(starspace_embeddings_cornell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (79464, 100)\n"
     ]
    }
   ],
   "source": [
    "q_matrix_cornell = get_q_matrix(data_cornell, starspace_embeddings_cornell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['how are you', 'scarred for life thats how i am'],\n",
      " ['how are you', 'very well thank you'],\n",
      " ['how are you honeybunch', 'is penelope in'],\n",
      " ['how are you', 'head still secure to the neck'],\n",
      " ['how are you', 'fine cant you see so yourself'],\n",
      " ['how are you', 'fine fine'],\n",
      " ['how are you', 'fine im fine how are you'],\n",
      " ['how are you', 'okay'],\n",
      " ['how are you', 'fine quite fine and your royal highness'],\n",
      " ['how are you', 'im okay'],\n",
      " ['how are you', 'good how are you'],\n",
      " ['how are you', 'all right son'],\n",
      " ['how are you', 'tired'],\n",
      " ['how are you', 'im just fine ally what about you'],\n",
      " ['how are you', 'i got fired'],\n",
      " ['how are you', 'another young man'],\n",
      " ['how are you', 'hello macaulay come in'],\n",
      " ['how are you', 'i hate to bother you when youre laid up'],\n",
      " ['how are you', 'fine']]\n"
     ]
    }
   ],
   "source": [
    "question = 'How are you?'\n",
    "answers_cornell = generate_answers(\n",
    "    question, data_cornell, q_matrix_cornell,\n",
    "    starspace_embeddings_cornell\n",
    ")\n",
    "pprint(answers_cornell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine answers. And similar to those got with pretrained Google vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique in pre-trained:\n",
      "[['cornelius how are you', 'bob im okay how are you'],\n",
      " ['wladek how are you', 'fine were fine thank you and you']]\n",
      "\n",
      "Unique in own-trained:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "unique_replicas_pretrained = (\n",
    "    [p for p in answers_pretrained if p not in answers_cornell])\n",
    "unique_replicas_owntrained = (\n",
    "    [p for p in answers_cornell if p not in answers_pretrained]\n",
    ")\n",
    "\n",
    "print('Unique in pre-trained:')\n",
    "pprint(unique_replicas_pretrained)\n",
    "\n",
    "print('\\nUnique in own-trained:')\n",
    "pprint(unique_replicas_owntrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we increase the dictionary size by setting `minCount` equal to 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starspace_embeddings_cornell_more_words = {}\n",
    "\n",
    "with open('./data/StarSpaceModelCornellMoreWords.tsv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for l in lines:\n",
    "    l = l.strip().split()\n",
    "    if len(l) <= 1:\n",
    "        continue\n",
    "    starspace_embeddings_cornell_more_words[l[0]] = np.array([float(el) for el in l[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30685"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(starspace_embeddings_cornell_more_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (79464, 100)\n"
     ]
    }
   ],
   "source": [
    "q_matrix_cornell_more_words = (\n",
    "    get_q_matrix(data_cornell, starspace_embeddings_cornell_more_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['how are you', 'scarred for life thats how i am'],\n",
      " ['how are you', 'very well thank you'],\n",
      " ['how are you', 'head still secure to the neck'],\n",
      " ['how are you', 'fine cant you see so yourself'],\n",
      " ['how are you', 'fine fine'],\n",
      " ['how are you', 'fine im fine how are you'],\n",
      " ['how are you', 'okay'],\n",
      " ['how are you', 'fine quite fine and your royal highness'],\n",
      " ['how are you', 'im okay'],\n",
      " ['how are you', 'good how are you'],\n",
      " ['how are you', 'all right son'],\n",
      " ['how are you', 'tired'],\n",
      " ['how are you', 'im just fine ally what about you'],\n",
      " ['how are you', 'i got fired'],\n",
      " ['how are you', 'another young man'],\n",
      " ['how are you', 'hello macaulay come in'],\n",
      " ['how are you', 'i hate to bother you when youre laid up'],\n",
      " ['how are you', 'fine']]\n"
     ]
    }
   ],
   "source": [
    "question = 'How are you?'\n",
    "answers_cornell_more_words = generate_answers(\n",
    "    question, data_cornell, q_matrix_cornell_more_words,\n",
    "    starspace_embeddings_cornell_more_words\n",
    ")\n",
    "pprint(answers_cornell_more_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "unique_replicas = (\n",
    "    [p for p in answers_cornell_more_words if p not in answers_cornell]\n",
    ")\n",
    "pprint(unique_replicas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we try to combine OpenSubs and Cornell datasets?\n",
    "Let's try searching answers in OpenSubs using vectors from Cornell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['we re adventurers sir', 'pursuing an opportunity']]\n"
     ]
    }
   ],
   "source": [
    "question = 'How are you?'\n",
    "answers_opensubs_using_cornell = generate_answers(\n",
    "    question, data_opensubs, q_matrix_opensubs,\n",
    "    starspace_embeddings_cornell\n",
    ")\n",
    "pprint(answers_opensubs_using_cornell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad, but quite a few.\n",
    "\n",
    "Let's try visa versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['well of course wed be honored', 'just putting in an appearance then']]\n"
     ]
    }
   ],
   "source": [
    "question = 'How are you?'\n",
    "answers_cornell_using_opensubs = generate_answers(\n",
    "    question, data_cornell, q_matrix_cornell,\n",
    "    starspace_embeddings_opensubs\n",
    ")\n",
    "pprint(answers_cornell_using_opensubs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, results definitely not so good as when using Cornell only.\n",
    "\n",
    "We tried just one question in all the cases, but I think that this one, 'How are you?', is quite common, and we can judge our models using it.\n",
    "\n",
    "So, in the bot we're going to use Cornell dataset (with `minCount 2`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Generative Model: N-gram Language Model\"></a>Generative Model: N-gram Language Model\n",
    "---\n",
    "Based on [the Notebook](http://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139) by Yoav Goldberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use \"^\" to mark beginning of a question in each question-answer pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_char_lm(file_path, order=4):\n",
    "    data = ''\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        # No need for end of statement symbol, point \".\" represents it\n",
    "        data += r'^' * order + line\n",
    "    \n",
    "    lm = defaultdict(Counter)\n",
    "    \n",
    "    for i in range(len(data) - order):\n",
    "        history = data[i:i+order]\n",
    "        char = data[i + order]\n",
    "        lm[history][char] += 1\n",
    "    \n",
    "    def normalize(counter):\n",
    "        s = float(sum(counter.values()))\n",
    "        return [(c, val / s) for c, val in list(counter.items())]\n",
    "    \n",
    "    lm_normalized = {h: normalize(chars) for h, chars in list(lm.items())}\n",
    "    \n",
    "    return lm_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare txt files for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'data_prepared_cornell.txt'), 'w') as f:\n",
    "    for pair in data_cornell:\n",
    "        f.write(pair[0] + '? ' + pair[1] + '.\\n')\n",
    "\n",
    "with open(os.path.join('data', 'data_prepared_opnesubs.txt'), 'w') as f:\n",
    "    for pair in data_opensubs:\n",
    "        f.write(pair[0] + '? ' + pair[1] + '.\\n')\n",
    "\n",
    "qa_file_txt = os.path.join('data', 'data_prepared_cornell.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = train_char_lm(qa_file_txt, order=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('l', 0.9816625916870416), ('o', 0.018337408312958436)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kill\n",
    "lm[' kil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 0.075),\n",
       " ('n', 0.721875),\n",
       " ('m', 0.06875),\n",
       " ('o', 0.09375),\n",
       " ('p', 0.003125),\n",
       " ('e', 0.021875),\n",
       " ('?', 0.003125),\n",
       " (' ', 0.009375),\n",
       " ('.', 0.003125)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# damn\n",
    "lm[' dam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_letter(lm, history, order):\n",
    "    history = history[-order:]\n",
    "    distribution = lm[history]\n",
    "\n",
    "    symbols = [p[0] for p in distribution]\n",
    "    probabilities = [p[1] for p in distribution]\n",
    "\n",
    "    return np.random.choice(symbols, size=1, p=probabilities)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text(lm, order, num_letters=1000):\n",
    "    history = r'^' * order\n",
    "    result = []\n",
    "    \n",
    "    for i in range(num_letters):\n",
    "        c = generate_letter(lm, history, order)\n",
    "        history = history[-order:] + c\n",
    "        # Don't want special character in the result\n",
    "        if not c == r'^':\n",
    "            result.append(c)\n",
    "    \n",
    "    return ''.join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some text samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whaits no you.\n",
      "but we an six.\n",
      "base do give mmuch? inight ar thim.\n",
      "you whor welier? to gaid.\n",
      "your beg be mork.\n",
      "for the you ter max bul do wask ah.\n",
      "why whouver see it? a by bets givere st to hered youver and bring a whant you to she broble sho is bethrod a i not dont king liken this wassickunds tow hoseed alks a bir arant you what i hind care st kno they eepieven if ill its was.\n",
      "you ont there yourdere becrom? do i.\n",
      "ho away.\n",
      "finings mov nou han row did jim thin.\n",
      "no gen.\n",
      "don.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(qa_file_txt, order=2)\n",
    "print(generate_text(lm, 2, num_letters=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i shouldnt some on of our kid? jimmy take serial good.\n",
      "you want the sixteen.\n",
      "youll be his is the daglio.\n",
      "mr girl yeah ill god? hi.\n",
      "turday? with i meat.\n",
      "youryouth me probably are you sure.\n",
      "yeah about something here? aparty? it neck bye danderthe bid.\n",
      "what one is.\n",
      "whats so be a wine.\n",
      "outside the gun shes offee score you sure? what piano.\n",
      "sure? i missing animal.\n",
      "whawhat about a maybe mum? valhall right? right? it want next tired? looks like the geomethink\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(qa_file_txt, order=4)\n",
    "print(generate_text(lm, 4, num_letters=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only the best quality you have any idea.\n",
      "here come on.\n",
      "danger? yes.\n",
      "dont say my name.\n",
      "i dont know? is it long im going to be great? do you want.\n",
      "smythe youve been love.\n",
      "good youre anatomically correct? and also with you.\n",
      "very good one ma.\n",
      "yes go away? i didnt know that.\n",
      "i never thought you hated sidnaw? just taste that christmas music.\n",
      "ow? im going to do? bill have it.\n",
      "no way no day? giv\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(qa_file_txt, order=10)\n",
    "print(generate_text(lm, 10, num_letters=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_answers_ngram(question, num_answers=5, max_iter=1000):\n",
    "    prepared_question = text_prepare(question)\n",
    "    phrase_in = r'^' + prepared_question + '? '\n",
    "    \n",
    "    num_symbols = len([l for l in phrase_in])\n",
    "    \n",
    "    # Question may be quite big\n",
    "    # Bigger history -> longer process (and higher chances of zero probabilities)\n",
    "    order = min(10, num_symbols)\n",
    "    \n",
    "    lm = train_char_lm(qa_file_txt, order=order)\n",
    "    \n",
    "    result = []\n",
    "    current_iteration = 0\n",
    "    # (3 * num_answers) -- just need something bigger than num_answers\n",
    "    while len(result) < num_answers and current_iteration < 3 * num_answers:\n",
    "        history = phrase_in[-order:]\n",
    "        symbols_out = []\n",
    "        c = ''\n",
    "        i = 0\n",
    "\n",
    "        while c != '.' and i < max_iter:\n",
    "            c = generate_letter(lm, history, order)\n",
    "            history = history[-order:] + c\n",
    "            if c != r'^':\n",
    "                symbols_out.append(c)\n",
    "            i += 1\n",
    "\n",
    "        symbols_out = symbols_out[:-1] # exclude point \".\"\n",
    "        phrase_out = ''.join(symbols_out)\n",
    "        \n",
    "        if phrase_out not in result:\n",
    "            result.append(phrase_out)\n",
    "        \n",
    "        current_iteration += 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thirty ones and two tens',\n",
       " 'can you move at all? you working on it',\n",
       " 'thats for sure? such as',\n",
       " 'ben where do you live with us',\n",
       " 'alvy alvy singer over here a moment']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'How are you?'\n",
    "generate_answers_ngram(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different answers — because of the probabilities behind the `generate_letter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['youre sure mr brandon? dont be afraid',\n",
       " 'yes',\n",
       " 'youre leaving you want me to? yes yours got them in your sleep? next time itll be our legacy? it will',\n",
       " 'some of the others werent there high school',\n",
       " 'youre not leaving without you']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'I want to drink your blood'\n",
    "generate_answers_ngram(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"youre sure mr brandon? dont be afraid\" :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Generative Model: LSTM-Based Language Model\"></a>Generative Model: LSTM-Based Language Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [code](https://gist.github.com/karpathy/d4dee566867f8291f086) by [Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines_cornell = open(os.path.join('data', 'data_prepared_cornell.txt'), 'r').readlines()\n",
    "lines_opensubs = open(os.path.join('data', 'data_prepared_opensubs.txt'), 'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79464, 766016)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines_cornell), len(lines_opensubs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cornell is much smaller. Let's copy some of Cornell's lines, mix lines in each dataset and then combine all lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines_cornell = lines_cornell * np.int(len(lines_opensubs) / len(lines_cornell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "715176"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines_cornell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(lines_cornell)\n",
    "np.random.shuffle(lines_opensubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all night? well who are those guys.\n",
      "hey how much are we ahead? approximately one thousand bucks.\n",
      "was it swine? no it was a seven letter word.\n",
      "five times a day? i guess its all got to do with this shop\n"
     ]
    }
   ],
   "source": [
    "data = ''.join(lines_cornell + lines_opensubs)\n",
    "data = data[:200000] # take a fragment\n",
    "\n",
    "print(data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 200000 characters, 40 unique.\n"
     ]
    }
   ],
   "source": [
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "\n",
    "print('Data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "\n",
    "char_to_ix = {c: i for i, c in enumerate(chars)}\n",
    "ix_to_char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 100    # size of hidden layer of neurons\n",
    "seq_length = 25      # number of steps to unroll the RNN for\n",
    "learning_rate = 1e-1\n",
    "\n",
    "# Model parameters\n",
    "Wxh = np.random.randn(hidden_size, vocab_size) * 0.01  # input to hidden\n",
    "Whh = np.random.randn(hidden_size, hidden_size) * 0.01 # hidden to hidden\n",
    "Why = np.random.randn(vocab_size, hidden_size) * 0.01  # hidden to output\n",
    "bh = np.zeros((hidden_size, 1))                        # hidden bias\n",
    "by = np.zeros((vocab_size, 1))                         # output bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lossFun(inputs, targets, hprev):\n",
    "    \"\"\"inputs, targets -- lists of integers\n",
    "       hprev -- Hx1 array of initial hidden state\n",
    "       ---\n",
    "       result -- the loss, gradients on model parameters,\n",
    "           and last hidden state\"\"\"\n",
    "    xs, hs, ys, ps = {}, {}, {}, {}\n",
    "    hs[-1] = np.copy(hprev)\n",
    "    loss = 0\n",
    "    \n",
    "    # Forward pass\n",
    "    for t in range(len(inputs)):\n",
    "        # Encode in 1-of-k representation\n",
    "        xs[t] = np.zeros((vocab_size,1))\n",
    "        xs[t][inputs[t]] = 1\n",
    "        \n",
    "        # Hidden state\n",
    "        hs[t] = np.tanh(\n",
    "            np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh\n",
    "        )\n",
    "        \n",
    "        # Unnormalized log probabilities for next chars\n",
    "        ys[t] = np.dot(Why, hs[t]) + by\n",
    "        \n",
    "        # Probabilities for next chars\n",
    "        ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t]))\n",
    "        \n",
    "        # Softmax (cross-entropy loss)\n",
    "        loss += -np.log(ps[t][targets[t],0])\n",
    "    \n",
    "    # Backward pass: compute gradients going backwards\n",
    "    dWxh, dWhh, dWhy = (\n",
    "        np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "    )\n",
    "    dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "    dhnext = np.zeros_like(hs[0])\n",
    "    \n",
    "    for t in reversed(range(len(inputs))):\n",
    "        dy = np.copy(ps[t])\n",
    "        \n",
    "        # Backprop into y\n",
    "        dy[targets[t]] -= 1\n",
    "        dWhy += np.dot(dy, hs[t].T)\n",
    "        dby += dy\n",
    "        \n",
    "        # Backprop into h\n",
    "        dh = np.dot(Why.T, dy) + dhnext\n",
    "        \n",
    "        # Backprop through tanh nonlinearity\n",
    "        dhraw = (1 - hs[t] * hs[t]) * dh\n",
    "        dbh  += dhraw\n",
    "        dWxh += np.dot(dhraw, xs[t].T)\n",
    "        dWhh += np.dot(dhraw, hs[t-1].T)\n",
    "        dhnext = np.dot(Whh.T, dhraw)\n",
    "    \n",
    "    for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "        # Clip to mitigate exploding gradients\n",
    "        np.clip(dparam, -5, 5, out=dparam)\n",
    "    \n",
    "    return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(h, seed_ix, n):\n",
    "    \"\"\"sample a sequence of integers from the model\n",
    "       ---\n",
    "       h -- memory state\n",
    "       seed_ix -- seed letter for first time step\"\"\"\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[seed_ix] = 1\n",
    "    ixes = []\n",
    "    \n",
    "    for t in range(n):\n",
    "        h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "        y = np.dot(Why, h) + by\n",
    "        p = np.exp(y) / np.sum(np.exp(y))\n",
    "        ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "        x = np.zeros((vocab_size, 1))\n",
    "        x[ix] = 1\n",
    "        ixes.append(ix)\n",
    "        \n",
    "    return ixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, loss: 92.160156\n",
      "iter 50000, loss: 50.521910\n",
      "iter 100000, loss: 48.574454\n",
      "iter 150000, loss: 47.864013\n",
      "iter 200000, loss: 47.274272\n",
      "iter 250000, loss: 47.503328\n",
      "iter 300000, loss: 46.707740\n",
      "iter 350000, loss: 46.528753\n",
      "iter 400000, loss: 46.183791\n",
      "iter 450000, loss: 46.606257\n",
      "iter 500000, loss: 46.012872\n",
      "iter 550000, loss: 45.857060\n",
      "iter 600000, loss: 45.650703\n",
      "iter 650000, loss: 46.031259\n",
      "iter 700000, loss: 45.507952\n",
      "iter 750000, loss: 45.447371\n",
      "iter 800000, loss: 46.264016\n",
      "iter 850000, loss: 46.398521\n",
      "iter 900000, loss: 45.954761\n",
      "iter 950000, loss: 45.539966\n",
      "Wall time: 55min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training\n",
    "\n",
    "n, p = 0, 0\n",
    "mWxh, mWhh, mWhy = (\n",
    "    np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    ")\n",
    "\n",
    "# Memory variables for Adagrad\n",
    "mbh, mby = np.zeros_like(bh), np.zeros_like(by)\n",
    "\n",
    "# Loss at iteration 0\n",
    "smooth_loss = -np.log(1.0 / vocab_size) * seq_length\n",
    "\n",
    "while n < 1_000_000:\n",
    "    # Prepare inputs (sweeping from left to right in steps seq_length long)\n",
    "    if p + seq_length + 1 >= len(data) or n == 0: \n",
    "        hprev = np.zeros((hidden_size, 1)) # reset RNN memory\n",
    "        p = 0                              # go from start of data\n",
    "    inputs =  [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
    "    targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
    "\n",
    "    # Sample from the model now and then\n",
    "    if n % 1000 == 0:\n",
    "        sample_ix = sample(hprev, inputs[0], 200)\n",
    "        txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "        # print('----\\n %s \\n----' % (txt, ))\n",
    "\n",
    "    # Forward seq_length characters through the net and fetch gradient\n",
    "    loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossFun(inputs, targets, hprev)\n",
    "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "    \n",
    "    # Print progress\n",
    "    if n % 50000 == 0:\n",
    "        print('iter %d, loss: %f' % (n, smooth_loss))\n",
    "        \n",
    "        # Backup\n",
    "        with open(os.path.join('data', 'net_params.txt'), 'w') as f:\n",
    "            f.write(json.dumps({\n",
    "                'Wxh': Wxh.tolist(),\n",
    "                'Whh': Whh.tolist(),\n",
    "                'Why': Why.tolist(),\n",
    "                'bh' : bh.tolist(),\n",
    "                'by' : by.tolist()\n",
    "            }))\n",
    "            f.write('\\n')\n",
    "\n",
    "    # Perform parameter update with Adagrad\n",
    "    for param, dparam, mem in zip([Wxh, Whh, Why, bh, by], \n",
    "                                  [dWxh, dWhh, dWhy, dbh, dby], \n",
    "                                  [mWxh, mWhh, mWhy, mbh, mby]):\n",
    "        mem   += dparam * dparam\n",
    "        param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update\n",
    "    \n",
    "    p += seq_length # move data pointer\n",
    "    n += 1          # iteration counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_answers_lstm(question): \n",
    "    question = text_prepare(question)\n",
    "    inputs =  [char_to_ix[ch] for ch in question]\n",
    "    \n",
    "    num_symbols_to_generate = 5 * len(inputs)\n",
    "    \n",
    "    hprev = np.zeros((hidden_size, 1))\n",
    "\n",
    "    sample_ix = sample(hprev, inputs[0], num_symbols_to_generate)\n",
    "    answer = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "    \n",
    "    # If there is still a piece of question at the beginning\n",
    "    #   we'll delete it from the answer\n",
    "    try:\n",
    "        answer = answer[answer.index('?')+1:]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Save only text from beginning till point (excluding)\n",
    "    try:\n",
    "        answer = answer[:answer.index('.')]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "hop are youre here habt to have a toet\n"
     ]
    }
   ],
   "source": [
    "question = 'How are you?'\n",
    "answer_lstm = generate_answers_lstm(question)\n",
    "print(answer_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it doesn't make much sence. So let's just make a bot without neural network answers :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Dialogue Example\"></a>Dialogue Example\n",
    "---\n",
    "\n",
    "Here is an example of a dialog with Bot (generated by running `ChatBot.py` as main program)\n",
    "\n",
    "- How are you?    \n",
    "  fine cant you see so yourself\n",
    "\n",
    "\n",
    "- What's is your name?  \n",
    "  Dale. Dale Barbara\n",
    "\n",
    "\n",
    "- I want something to drink  \n",
    "  mmm... sorry, i've forgot anything about it\n",
    "\n",
    "\n",
    "- Where can I buy a guitar?  \n",
    "  sorry, i don't know...\n",
    "\n",
    "\n",
    "- What will the weather be like tomorrow?   \n",
    "  how did you get in here\n",
    "\n",
    "\n",
    "- Nice shot!   \n",
    "  thank you sir\n",
    "\n",
    "\n",
    "- How old are you?  \n",
    "  Well, you know, I'm a bot actually. There is no such a notion for me as age. I' supposed to tell you that I'm 30 years old. But my programm's been running for a just couple of days\n",
    "\n",
    "\n",
    "- Tell me something I don't know    \n",
    "  a deer\n",
    "\n",
    "\n",
    "- Do you like The Godfather movie?  \n",
    "  very much\n",
    "\n",
    "\n",
    "- Let's rob a bank, Billy!  \n",
    "  what a coincidence! i also want to know the answer to this question\n",
    "\n",
    "\n",
    "- Bye  \n",
    "  have a nice outing you lot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1.0,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0.0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}